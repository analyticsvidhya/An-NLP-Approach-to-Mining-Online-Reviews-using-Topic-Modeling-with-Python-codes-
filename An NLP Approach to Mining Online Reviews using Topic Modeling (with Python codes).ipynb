{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Implementation  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import FreqDist\n",
    "nltk.download('stopwords') # run this one time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "import numpy as np\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "\n",
    "# libraries for visualization\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('Automotive_5.json', lines=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to plot most frequent terms\n",
    "def freq_words(x, terms = 30):\n",
    "  all_words = ' '.join([text for text in x])\n",
    "  all_words = all_words.split()\n",
    "\n",
    "  fdist = FreqDist(all_words)\n",
    "  words_df = pd.DataFrame({'word':list(fdist.keys()), 'count':list(fdist.values())})\n",
    "\n",
    "  # selecting top 20 most frequent words\n",
    "  d = words_df.nlargest(columns=\"count\", n = terms) \n",
    "  plt.figure(figsize=(20,5))\n",
    "  ax = sns.barplot(data=d, x= \"word\", y = \"count\")\n",
    "  ax.set(ylabel = 'Count')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_words(df['reviewText'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unwanted characters, numbers and symbols\n",
    "df['reviewText'] = df['reviewText'].str.replace(\"[^a-zA-Z#]\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to remove stopwords\n",
    "def remove_stopwords(rev):\n",
    "    rev_new = \" \".join([i for i in rev if i not in stop_words])\n",
    "    return rev_new\n",
    "\n",
    "# remove short words (length < 3)\n",
    "df['reviewText'] = df['reviewText'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>2]))\n",
    "\n",
    "# remove stopwords from the text\n",
    "reviews = [remove_stopwords(r.split()) for r in df['reviewText']]\n",
    "\n",
    "# make entire text lowercase\n",
    "reviews = [r.lower() for r in reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_words(reviews, 35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en # one time run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "\n",
    "def lemmatization(texts, tags=['NOUN', 'ADJ']): # filter noun and adjective\n",
    "       output = []\n",
    "       for sent in texts:\n",
    "             doc = nlp(\" \".join(sent)) \n",
    "             output.append([token.lemma_ for token in doc if token.pos_ in tags])\n",
    "       return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_reviews = pd.Series(reviews).apply(lambda x: x.split())\n",
    "print(tokenized_reviews[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_2 = lemmatization(tokenized_reviews)\n",
    "print(reviews_2[1]) # print lemmatized review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_3 = []\n",
    "for i in range(len(reviews_2)):\n",
    "    reviews_3.append(' '.join(reviews_2[i]))\n",
    "\n",
    "df['reviews'] = reviews_3\n",
    "\n",
    "freq_words(df['reviews'], 35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building an LDA model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(reviews_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_term_matrix = [dictionary.doc2bow(rev) for rev in reviews_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the object for LDA model using gensim library\n",
    "LDA = gensim.models.ldamodel.LdaModel\n",
    "\n",
    "# Build LDA model\n",
    "lda_model = LDA(corpus=doc_term_matrix, id2word=dictionary, num_topics=7, random_state=100,\n",
    "                chunksize=1000, passes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topics Visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, doc_term_matrix, dictionary)\n",
    "vis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
